{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quang task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quan task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "from sklearn import neighbors, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "path = \"/content/Number_dataset\"\n",
    "for name in os.listdir(path):\n",
    "    path_numbers = path + \"/\" + name\n",
    "    for img_name in os.listdir(path_numbers):\n",
    "        img = cv2.imread(path_numbers + \"/\" + img_name)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.resize(img_gray, (280, 280))\n",
    "        _, thresh2 = cv2.threshold(img_gray, 130, 255, cv2.THRESH_BINARY_INV)\n",
    "        img_ss2 = cv2.dilate(thresh2, kernel, iterations = 4)\n",
    "        img_ss2 = cv2.erode(img_ss2, kernel, iterations = 1)\n",
    "        closing = cv2.morphologyEx(img_ss2, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
    "        closing = cv2.dilate(closing, kernel, iterations = 1)\n",
    "        img_reshape = cv2.resize(closing, (28, 28))\n",
    "        X_number = np.array(img_reshape).reshape((784))\n",
    "        X.append(X_number)\n",
    "        y.append(int(name))\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3333)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.142857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "size_train, _ = X_train.shape\n",
    "size_val, _ = X_val.shape\n",
    "size_test, _ = X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_predict))\n",
    "print(y_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (size_train, 28, 28, 1))\n",
    "X_val = np.reshape(X_val, (size_val, 28, 28, 1))\n",
    "X_test = np.reshape(X_test, (size_test, 28, 28, 1))\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test_cnn = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(32, (5,5), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2), strides = 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(64, (3,3), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = activations.relu))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = activations.softmax))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "filepath=\"/content/best_checkpoint\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "epoch = 100\n",
    "batch_size = 112\n",
    "model.fit(x = X_train, y = y_train, batch_size = batch_size, epochs = epoch, callbacks = [], validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_raw = model.predict(X_test)\n",
    "y_predict = y_predict_raw.argmax(axis = 1)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predict))\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predict)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trinh task"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
