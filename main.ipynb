{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quang task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quan task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from keras.datasets import mnist\n",
    "from sklearn import neighbors, metrics, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m img_name \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(path_numbers):\n\u001b[0;32m      9\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(path_numbers \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m img_name)\n\u001b[1;32m---> 10\u001b[0m     img_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[0;32m     11\u001b[0m     img_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img_gray, (\u001b[39m280\u001b[39m, \u001b[39m280\u001b[39m))\n\u001b[0;32m     12\u001b[0m     _, thresh2 \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mthreshold(img_gray, \u001b[39m130\u001b[39m, \u001b[39m255\u001b[39m, cv2\u001b[39m.\u001b[39mTHRESH_BINARY_INV)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "path = \"/content/CS114.N21/Datasets\"\n",
    "\n",
    "imgPaths = []\n",
    "\n",
    "for name in os.listdir(path):\n",
    "    path_numbers = path + \"/\" + name\n",
    "    for img_name in os.listdir(path_numbers):\n",
    "        imgPath = path_numbers + \"/\" + img_name\n",
    "        img = cv2.imread(imgPath)\n",
    "        imgPaths.append(imgPath)\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.resize(img_gray, (280, 280))\n",
    "        _, thresh2 = cv2.threshold(img_gray, 130, 255, cv2.THRESH_BINARY_INV)\n",
    "        img_ss2 = cv2.dilate(thresh2, kernel, iterations = 4)\n",
    "        img_ss2 = cv2.erode(img_ss2, kernel, iterations = 1)\n",
    "        closing = cv2.morphologyEx(img_ss2, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
    "        closing = cv2.dilate(closing, kernel, iterations = 1)\n",
    "        img_reshape = cv2.resize(closing, (28, 28))\n",
    "        X_number = np.array(img_reshape).reshape((784))\n",
    "        X.append(X_number)\n",
    "        y.append(int(name))\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imgPath_train, X_imgPath_test, y_train, y_test = train_test_split(list(zip(X, imgPaths)), y, test_size = 0.3333)\n",
    "X_train = np.array([x_imgPath[0] for x_imgPath in X_imgPath_train])\n",
    "X_test = np.array([x_imgPath[0] for x_imgPath in X_imgPath_test])\n",
    "imgPath_test = np.array([x_imgPath[1] for x_imgPath in X_imgPath_test])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.142857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, X_val.shape)\n",
    "size_train, _ = X_train.shape\n",
    "size_val, _ = X_val.shape\n",
    "size_test, _ = X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors = 3, p = 2)\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_predict))\n",
    "print(y_test)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (size_train, 28, 28, 1))\n",
    "X_val = np.reshape(X_val, (size_val, 28, 28, 1))\n",
    "X_test = np.reshape(X_test, (size_test, 28, 28, 1))\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test_cnn = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(32, (5,5), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2), strides = 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(64, (3,3), activation = activations.relu, padding = 'same', input_shape = (28, 28, 1)))\n",
    "model.add(MaxPooling2D((2,2), strides = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = activations.relu))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation = activations.softmax))\n",
    "\n",
    "model.summary()\n",
    "# fit model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "epoch = 30\n",
    "batch_size = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "filepath=\"/content/best_checkpoint\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "epoch = 30\n",
    "batch_size = 112\n",
    "model.fit(x = X_train, y = y_train, batch_size = batch_size, epochs = epoch, callbacks = [], validation_data = (X_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Classification report for classifier {clf}:\\n\"\n",
    "    f\"{metrics.classification_report(y_test, y_predict)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_predict)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dữ liệu về tỉ lệ đúng/sai của các cột\n",
    "correct = [len([i for i, y in enumerate(y_test) if y == num and y == y_predict[i]]) for num in range(10)]\n",
    "incorrect = [len([i for i, y in enumerate(y_test) if y == num and y != y_predict[i]]) for num in range(10)]\n",
    "\n",
    "correctRatio = [cor / (cor + incor) for cor, incor in zip(correct, incorrect)]\n",
    "incorrectRatio = [1 - cor for cor in correctRatio]\n",
    "\n",
    "# Labels cho các cột\n",
    "# labels = ['Cột 1', 'Cột 2', 'Cột 3', 'Cột 4', 'Cột 5']\n",
    "labels = list(range(10))\n",
    "\n",
    "# Tạo một Figure và Axes\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Vẽ biểu đồ cột ngang\n",
    "ax.barh(labels, correctRatio, label='Đúng', color='green')\n",
    "ax.barh(labels, incorrectRatio, left=correctRatio, label='Sai', color='red')\n",
    "\n",
    "# Đặt tiêu đề và nhãn trục\n",
    "ax.set_title('Tỉ lệ đúng/sai của các chữ số')\n",
    "ax.set_xlabel('Tỉ lệ')\n",
    "ax.set_ylabel('Chữ số')\n",
    "\n",
    "# Hiển thị chú thích\n",
    "ax.legend()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiểm tra kết quả sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị các ảnh bị dự đoán sai kèm theo nhãn dự đoán\n",
    "rowShow = 3 \n",
    "figWidthShow = 18\n",
    "subFigHeightShow = 3\n",
    "\n",
    "def showRawImg_ExtractedData_Labels(rawImgs, extractedDatas, actLabels, predLabels):\n",
    "    itemCount = len(actLabels)\n",
    "\n",
    "    rowCount = itemCount // rowShow + 1 if itemCount % rowShow else itemCount // rowShow\n",
    "    figSizeShow = (figWidthShow, subFigHeightShow * rowCount) # số đầu là chiều ngang, sau: chiều dọc\n",
    "\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots( itemCount // rowShow + 1 if itemCount % rowShow else itemCount // rowShow, rowShow * 3, figsize=figSizeShow)\n",
    "    # fig, axes = plt.subplots( itemCount // rowShow + 1 if itemCount % rowShow else itemCount // rowShow, rowShow * 3)\n",
    "    print(rowShow * 3, itemCount // rowShow + 1 if itemCount % rowShow else itemCount // rowShow)\n",
    "    # rawImgs, extractedDatas, labels\n",
    "    for i in range(itemCount):\n",
    "        _x = i // rowShow # số hàng\n",
    "        _y = i % rowShow # số cột\n",
    "\n",
    "        # show raw img\n",
    "        ax = axes[_x, _y * 3]\n",
    "        # ax.imshow(rawImgs[i], cmap='gray')\n",
    "        img = Image.open(rawImgs[i])\n",
    "        ax.imshow(img)\n",
    "        # ax.imshow(rawImgs[i], cmap='gray', aspect='auto')\n",
    "\n",
    "        # show extracted img\n",
    "        ax = axes[_x, _y * 3 + 1]\n",
    "        ax.imshow(extractedDatas[i], cmap='gray')\n",
    "        # show label\n",
    "        ax = axes[_x, _y * 3 + 2]\n",
    "        # ax.text(0.5, 0.5, 'Predicted: {} \\n Actual: {}'.format(actLabels[i], predLabels[i]), ha='left', va='center', fontsize=20)\n",
    "        ax.text(0.5, 0.5, f'Actual: {actLabels[i]} \\n Predicted: {predLabels[i]}', ha='center', va='center', fontsize=20)\n",
    "        ax.axis('off')\n",
    "    # xoá mấy cái cạnh ở cuối\n",
    "    for i in range(itemCount % rowShow, rowShow):\n",
    "        _y = i % rowShow # số cột\n",
    "        for j in range(3):\n",
    "            ax = axes[rowCount - 1, _y * 3 + j]\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showRawImg_ExtractedData_Labels_N(rawImgs, extractedDatas, actLabels, predLabels, index):\n",
    "    showRawImg_ExtractedData_Labels(\n",
    "        rawImgs[index], \n",
    "        extractedDatas[index], \n",
    "        actLabels[index],\n",
    "        predLabels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_indices = np.where(y_predict != y_test)[0]\n",
    "print(f\"Số lượng dự đoán sai: {len(misclassified_indices)}/{len(y_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_test = X_test.reshape((514, 28, 28))\n",
    "\n",
    "# showRawImg_ExtractedData_Labels_N(_X_test, _X_test, y_test, y_predict, misclassified_indices[10:50])\n",
    "showRawImg_ExtractedData_Labels_N(imgPath_test, _X_test, y_test, y_predict, misclassified_indices[10:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
